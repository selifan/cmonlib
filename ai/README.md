# Модели, которые поместятся в 8 ГБ VRAM
Чем больше данных отправляется, тем больше они потребляют память. Рекомендуется изначально закладывать дополнительные 15% памяти поверх размера модели — в большинстве случаев этого должно хватать для комфортной работы.
* Llama 3.1 8B Instruct (Quantized) — хорошо работает с 4-битным квантованием (версия Q4_K_M помещается в 8 ГБ).
* Mistral 7B Instruct (Quantized) — хорошо работает с 4-битным квантованием.
* Phi-3 Mini / Small (Quantized) — небольшие модели (3,8B для Mini, 7B для Small) подходят для 8 ГБ-карт.
* Gemma 2B QAT / Gemma 7B QAT (Quantized) — хорошо помещается в 8 ГБ.
* DeepSeek-R1-Distill-Qwen-1.5B (Quantized) — лёгкая и быстрая, подходит для 8 ГБ-карт.
* Qwen 1.5 7B Q5_K_M. Размер файла модели — 5,53 ГБ. 
* Qwen2.5 7B. Общий размер модели — 4,7 ГБ, рекомендуемый объём VRAM — 6 ГБ. 
* StableLM 3B. 
* TinyLlama 1.1B. 
* DistilBERT. Модель с около 66 миллионами параметров, может работать на карте с объёмом VRAM 8 ГБ. 
* ALBERT. Модель разработана для эффективной работы с VRAM, использует технику совместного использования параметров, чтобы уменьшить необходимый объём памяти
