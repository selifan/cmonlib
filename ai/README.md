# Модели, которые поместятся в 8 ГБ VRAM
Чем больше данных отправляется, тем больше они потребляют память. Рекомендуется изначально закладывать дополнительные 15% памяти поверх размера модели — в большинстве случаев этого должно хватать для комфортной работы.
* Llama 3.1 8B Instruct (Quantized) — хорошо работает с 4-битным квантованием (версия Q4_K_M помещается в 8 ГБ).
* Mistral 7B Instruct (Quantized) — хорошо работает с 4-битным квантованием.
* Phi-3 Mini / Small (Quantized) — небольшие модели (3,8B для Mini, 7B для Small) подходят для 8 ГБ-карт.
* Gemma 2B QAT / Gemma 7B QAT (Quantized) — хорошо помещается в 8 ГБ.
* DeepSeek-R1-Distill-Qwen-1.5B (Quantized) — лёгкая и быстрая, подходит для 8 ГБ-карт.
